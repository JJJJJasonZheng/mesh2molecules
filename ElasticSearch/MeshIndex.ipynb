{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json as json\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search, Q\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting index mesh_cvd , Response: {'acknowledged': True}\n",
      "Create index mesh_cvd , Response: {'acknowledged': True, 'shards_acknowledged': True, 'index': 'mesh_cvd'}\n"
     ]
    }
   ],
   "source": [
    "INDEX_NAME = \"mesh_cvd\"\n",
    "NUMBER_SHARDS = 1 # keep this as one if no clusterNUMBER_REPLICAS = 0 \n",
    "NUMBER_REPLICAS = 0\n",
    "\n",
    "request_body = {\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": NUMBER_SHARDS,\n",
    "            \"number_of_replicas\": NUMBER_REPLICAS\n",
    "        },\n",
    "        \"mappings\": {\n",
    "                \"properties\": {\n",
    "                    \"id\":{\n",
    "                        \"type\": \"text\"\n",
    "                    },\n",
    "                    \"name\":{\n",
    "                        \"type\": \"text\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "\n",
    "es = Elasticsearch()\n",
    "\n",
    "if es.indices.exists(INDEX_NAME):\n",
    "     res = es.indices.delete(index = INDEX_NAME)\n",
    "     print(\"Deleting index %s , Response: %s\" % (INDEX_NAME, res))\n",
    "    \n",
    "res = es.indices.create(index = INDEX_NAME, body = request_body)\n",
    "print(\"Create index %s , Response: %s\" % (INDEX_NAME, res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CVD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "651"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvd = pd.read_csv('./cvd.csv')\n",
    "cvd = cvd.to_dict(orient='records')\n",
    "len(cvd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish meta-data indexing. Total escaped time 0.16572880744934082 (seconds) \n"
     ]
    }
   ],
   "source": [
    "logFilePath = \"log_cvd.txt\"\n",
    "\n",
    "INDEX_NAME = \"mesh_cvd\"\n",
    "\n",
    "es = Elasticsearch()\n",
    "\n",
    "ic = 0\n",
    "ir = 0\n",
    "\n",
    "with open(logFilePath, \"w\") as fout:\n",
    "        start = time.time()\n",
    "        bulk_size = 50 # number of document processed in each bulk index\n",
    "        bulk_data = [] # data in bulk index\n",
    "\n",
    "        cnt = 0\n",
    "        for item in cvd: ## each item is single document\n",
    "                cnt += 1\n",
    "                \n",
    "                data_dict = {}\n",
    "                \n",
    "                # update ID\n",
    "                data_dict[\"id\"] = item[\"id\"]\n",
    "\n",
    "                # update detail<------------------\n",
    "                data_dict['name'] = item['name']\n",
    "                \n",
    "                ## Put current data into the bulk <---------\n",
    "                op_dict = {\n",
    "                    \"index\": {\n",
    "                        \"_index\": INDEX_NAME,\n",
    "                        \"_id\": data_dict[\"id\"]\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                bulk_data.append(op_dict)\n",
    "                bulk_data.append(data_dict) \n",
    "                                        \n",
    "                ## Start Bulk indexing\n",
    "                if cnt % bulk_size == 0 and cnt != 0:\n",
    "                    ic += 1\n",
    "                    tmp = time.time()\n",
    "                    es.bulk(index=INDEX_NAME, body=bulk_data, request_timeout = 500)\n",
    "                    fout.write(\"bulk indexing... %s, escaped time %s (seconds) \\n\" \\\n",
    "                               % ( cnt, tmp - start ) )\n",
    "                    \n",
    "                    if ic%50 ==0:\n",
    "                        print(\" i bulk indexing... %s, escaped time %s (seconds) \" \\\n",
    "                              % ( cnt, tmp - start ) )\n",
    "                    \n",
    "                    \n",
    "                    bulk_data = []\n",
    "   \n",
    "        ## indexing those left papers\n",
    "        if bulk_data:\n",
    "            ir +=1\n",
    "            tmp = time.time()\n",
    "            es.bulk(index=INDEX_NAME, body=bulk_data, request_timeout = 500)\n",
    "            fout.write(\"bulk indexing... %s, escaped time %s (seconds) \\n\"\\\n",
    "                       % ( cnt, tmp - start ) )\n",
    "            \n",
    "            if ir%50 ==0:\n",
    "                print(\" r bulk indexing... %s, escaped time %s (seconds) \"\\\n",
    "                      % ( cnt, tmp - start ) )\n",
    "            bulk_data = []\n",
    "            \n",
    "        \n",
    "\n",
    "        end = time.time()\n",
    "        fout.write(\"Finish  meta-data indexing. Total escaped time %s (seconds) \\n\"\\\n",
    "                   % (end - start) )\n",
    "        print(\"Finish meta-data indexing. Total escaped time %s (seconds) \"\\\n",
    "              % (end - start) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'C14.907.952.880', 'name': 'Postthrombotic Syndrome'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'elasticsearch_dsl.search.Search'>\n",
      "<elasticsearch_dsl.search.Search object at 0x1162f9588>\n"
     ]
    }
   ],
   "source": [
    "es = Elasticsearch(timeout=300)\n",
    "k = 0\n",
    "Data = []\n",
    "\n",
    "entity = 'cardiovascular'\n",
    "\n",
    "s = Search(using=es, index='mesh_cvd')\\\n",
    "                    .params(request_timeout=300)\\\n",
    "                    .query(\"match_phrase\",name=entity)\n",
    "\n",
    "print(type(s))\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hit in s.scan():\n",
    "\n",
    "        ID = str(hit.id)\n",
    "        \n",
    "        name = str(hit.name)\n",
    "        \n",
    "        Data.append({\"ID\":ID,\\\n",
    "                     \"name\":name})      \n",
    "\n",
    "k = k +1\n",
    "if k%10 == 0:\n",
    "        print(k,'entity counted!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ID': 'C14', 'name': 'Cardiovascular Diseases'},\n",
       " {'ID': 'C14.240', 'name': 'Cardiovascular Abnormalities'},\n",
       " {'ID': 'C14.260', 'name': 'Cardiovascular Infections'},\n",
       " {'ID': 'C14.260.500', 'name': 'Syphilis, Cardiovascular'},\n",
       " {'ID': 'C14.260.750', 'name': 'Tuberculosis, Cardiovascular'},\n",
       " {'ID': 'C14.583', 'name': 'Pregnancy Complications, Cardiovascular'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
