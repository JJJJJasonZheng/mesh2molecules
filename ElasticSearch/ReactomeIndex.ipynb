{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json as json\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search, Q\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create index reactomepathway , Response: {'acknowledged': True, 'shards_acknowledged': True, 'index': 'reactomepathway'}\n"
     ]
    }
   ],
   "source": [
    "INDEX_NAME = \"reactomepathway\"\n",
    "NUMBER_SHARDS = 1 # keep this as one if no clusterNUMBER_REPLICAS = 0 \n",
    "NUMBER_REPLICAS = 0\n",
    "\n",
    "request_body = {\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": NUMBER_SHARDS,\n",
    "            \"number_of_replicas\": NUMBER_REPLICAS\n",
    "        },\n",
    "        \"mappings\": {\n",
    "                \"properties\": {\n",
    "                    \"id\":{\n",
    "                        \"type\": \"text\"\n",
    "                    },\n",
    "                    \"pathway\":{\n",
    "                        \"type\": \"text\"\n",
    "                    }\n",
    "                    \"species\":{\n",
    "                        \"type\": \"text\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "\n",
    "es = Elasticsearch()\n",
    "\n",
    "if es.indices.exists(INDEX_NAME):\n",
    "     res = es.indices.delete(index = INDEX_NAME)\n",
    "     print(\"Deleting index %s , Response: %s\" % (INDEX_NAME, res))\n",
    "    \n",
    "res = es.indices.create(index = INDEX_NAME, body = request_body)\n",
    "print(\"Create index %s , Response: %s\" % (INDEX_NAME, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactome = pd.read_table('./ReactomePathways.txt', sep='\\t', header=None)\n",
    "reactome = reactome.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " i bulk indexing... 2500, escaped time 0.797307014465332 (seconds) \n",
      " i bulk indexing... 5000, escaped time 1.460188865661621 (seconds) \n",
      " i bulk indexing... 7500, escaped time 2.0389161109924316 (seconds) \n",
      " i bulk indexing... 10000, escaped time 2.6908888816833496 (seconds) \n",
      " i bulk indexing... 12500, escaped time 3.2648189067840576 (seconds) \n",
      " i bulk indexing... 15000, escaped time 3.84694504737854 (seconds) \n",
      " i bulk indexing... 17500, escaped time 4.58211088180542 (seconds) \n",
      " i bulk indexing... 20000, escaped time 5.245260953903198 (seconds) \n",
      "Finish meta-data indexing. Total escaped time 5.601640939712524 (seconds) \n"
     ]
    }
   ],
   "source": [
    "logFilePath = \"log_reactome.txt\"\n",
    "\n",
    "INDEX_NAME = \"reactomepathway\"\n",
    "\n",
    "es = Elasticsearch()\n",
    "\n",
    "ic = 0\n",
    "ir = 0\n",
    "\n",
    "with open(logFilePath, \"w\") as fout:\n",
    "        start = time.time()\n",
    "        bulk_size = 50 # number of document processed in each bulk index\n",
    "        bulk_data = [] # data in bulk index\n",
    "\n",
    "        cnt = 0\n",
    "        for item in reactome: ## each item is single document\n",
    "                cnt += 1\n",
    "                \n",
    "                data_dict = {}\n",
    "                \n",
    "                # update ID\n",
    "                data_dict[\"id\"] = item[0]\n",
    "\n",
    "                # update detail<------------------\n",
    "                data_dict['pathway'] = item[1]\n",
    "                data_dict['species'] = item[2]\n",
    "                \n",
    "                ## Put current data into the bulk <---------\n",
    "                op_dict = {\n",
    "                    \"index\": {\n",
    "                        \"_index\": INDEX_NAME,\n",
    "                        \"_id\": data_dict[\"id\"]\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                bulk_data.append(op_dict)\n",
    "                bulk_data.append(data_dict) \n",
    "                                        \n",
    "                ## Start Bulk indexing\n",
    "                if cnt % bulk_size == 0 and cnt != 0:\n",
    "                    ic += 1\n",
    "                    tmp = time.time()\n",
    "                    es.bulk(index=INDEX_NAME, body=bulk_data, request_timeout = 500)\n",
    "                    fout.write(\"bulk indexing... %s, escaped time %s (seconds) \\n\" \\\n",
    "                               % ( cnt, tmp - start ) )\n",
    "                    \n",
    "                    if ic%50 ==0:\n",
    "                        print(\" i bulk indexing... %s, escaped time %s (seconds) \" \\\n",
    "                              % ( cnt, tmp - start ) )\n",
    "                    \n",
    "                    \n",
    "                    bulk_data = []\n",
    "   \n",
    "        ## indexing those left papers\n",
    "        if bulk_data:\n",
    "            ir +=1\n",
    "            tmp = time.time()\n",
    "            es.bulk(index=INDEX_NAME, body=bulk_data, request_timeout = 500)\n",
    "            fout.write(\"bulk indexing... %s, escaped time %s (seconds) \\n\"\\\n",
    "                       % ( cnt, tmp - start ) )\n",
    "            \n",
    "            if ir%50 ==0:\n",
    "                print(\" r bulk indexing... %s, escaped time %s (seconds) \"\\\n",
    "                      % ( cnt, tmp - start ) )\n",
    "            bulk_data = []\n",
    "            \n",
    "        \n",
    "\n",
    "        end = time.time()\n",
    "        fout.write(\"Finish  meta-data indexing. Total escaped time %s (seconds) \\n\"\\\n",
    "                   % (end - start) )\n",
    "        print(\"Finish meta-data indexing. Total escaped time %s (seconds) \"\\\n",
    "              % (end - start) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
